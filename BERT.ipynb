{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rtt6IUfZ2QOl"
   },
   "source": [
    "## One-time installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoz_4LhoNdjS"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCxX5ZQY1Iih"
   },
   "source": [
    "#### Download and install NVIDIA Apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 139213,
     "status": "ok",
     "timestamp": 1561604687967,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "PWHCFgUfu2Tw",
    "outputId": "bb5b9e39-3486-4f00-c4d9-add1399ce739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 168, done.\u001b[K\n",
      "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
      "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
      "remote: Total 4804 (delta 88), reused 117 (delta 63), pack-reused 4636\u001b[K\n",
      "Receiving objects: 100% (4804/4804), 8.79 MiB | 23.26 MiB/s, done.\n",
      "Resolving deltas: 100% (3100/3100), done.\n",
      "/content/apex\n",
      "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:244: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-b9p46jwv\n",
      "Created temporary directory: /tmp/pip-req-tracker-olo7w0e7\n",
      "Created requirements tracker '/tmp/pip-req-tracker-olo7w0e7'\n",
      "Created temporary directory: /tmp/pip-install-m52pmah3\n",
      "Processing /content/apex\n",
      "  Created temporary directory: /tmp/pip-req-build-xo_e1ag9\n",
      "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-olo7w0e7'\n",
      "    Running setup.py (path:/tmp/pip-req-build-xo_e1ag9/setup.py) egg_info for package from file:///content/apex\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.1.0\n",
      "    running egg_info\n",
      "    creating pip-egg-info/apex.egg-info\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-xo_e1ag9 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
      "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-olo7w0e7'\n",
      "Skipping bdist_wheel for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-5qwmxyua\n",
      "    Running command /usr/bin/python3 -u -c 'import setuptools, tokenize;__file__='\"'\"'/tmp/pip-req-build-xo_e1ag9/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-5qwmxyua/install-record.txt --single-version-externally-managed --compile\n",
      "    torch.__version__  =  1.1.0\n",
      "\n",
      "    Compiling cuda extensions with\n",
      "    nvcc: NVIDIA (R) Cuda compiler driver\n",
      "    Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "    Built on Sat_Aug_25_21:08:01_CDT_2018\n",
      "    Cuda compilation tools, release 10.0, V10.0.130\n",
      "    from /usr/local/cuda/bin\n",
      "\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/apex\n",
      "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
      "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
      "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
      "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
      "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
      "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
      "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
      "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
      "    running build_ext\n",
      "    building 'apex_C' extension\n",
      "    creating build/temp.linux-x86_64-3.6\n",
      "    creating build/temp.linux-x86_64-3.6/csrc\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'amp_C' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_adam_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'syncbn' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
      "    building 'fused_layer_norm_cuda' extension\n",
      "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
      "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
      "    running install_lib\n",
      "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
      "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
      "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
      "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
      "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-5qwmxyua/install-record.txt'\n",
      "  Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
      "  Removing source in /tmp/pip-req-build-xo_e1ag9\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "Removed build tracker '/tmp/pip-req-tracker-olo7w0e7'\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex\n",
    "% cd apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
    "% cd /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lj-TDb-P2UfL"
   },
   "source": [
    "#### Clone & install pretrained BERT repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 150923,
     "status": "ok",
     "timestamp": 1561604704398,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "nebCBnhhA0nP",
    "outputId": "286edc3a-90bd-4c0f-95f9-c57bf1729af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-pretrained-BERT'...\n",
      "remote: Enumerating objects: 3993, done.\u001b[K\n",
      "Receiving objects:   0% (1/3993)   \r",
      "Receiving objects:   1% (40/3993)   \r",
      "Receiving objects:   2% (80/3993)   \r",
      "Receiving objects:   3% (120/3993)   \r",
      "Receiving objects:   4% (160/3993)   \r",
      "Receiving objects:   5% (200/3993)   \r",
      "Receiving objects:   6% (240/3993)   \r",
      "Receiving objects:   7% (280/3993)   \r",
      "Receiving objects:   8% (320/3993)   \r",
      "Receiving objects:   9% (360/3993)   \r",
      "Receiving objects:  10% (400/3993)   \r",
      "Receiving objects:  11% (440/3993)   \r",
      "Receiving objects:  12% (480/3993)   \r",
      "Receiving objects:  13% (520/3993)   \r",
      "Receiving objects:  14% (560/3993)   \r",
      "Receiving objects:  15% (599/3993)   \r",
      "Receiving objects:  16% (639/3993)   \r",
      "Receiving objects:  17% (679/3993)   \r",
      "Receiving objects:  18% (719/3993)   \r",
      "Receiving objects:  19% (759/3993)   \r",
      "Receiving objects:  20% (799/3993)   \r",
      "Receiving objects:  21% (839/3993)   \r",
      "Receiving objects:  22% (879/3993)   \r",
      "Receiving objects:  23% (919/3993)   \r",
      "Receiving objects:  24% (959/3993)   \r",
      "Receiving objects:  25% (999/3993)   \r",
      "Receiving objects:  26% (1039/3993)   \r",
      "Receiving objects:  27% (1079/3993)   \r",
      "Receiving objects:  28% (1119/3993)   \r",
      "Receiving objects:  29% (1158/3993)   \r",
      "Receiving objects:  30% (1198/3993)   \r",
      "Receiving objects:  31% (1238/3993)   \r",
      "Receiving objects:  32% (1278/3993)   \r",
      "Receiving objects:  33% (1318/3993)   \r",
      "Receiving objects:  34% (1358/3993)   \r",
      "Receiving objects:  35% (1398/3993)   \r",
      "Receiving objects:  36% (1438/3993)   \r",
      "Receiving objects:  37% (1478/3993)   \r",
      "Receiving objects:  38% (1518/3993)   \r",
      "Receiving objects:  39% (1558/3993)   \r",
      "Receiving objects:  40% (1598/3993)   \r",
      "Receiving objects:  41% (1638/3993)   \r",
      "Receiving objects:  42% (1678/3993)   \r",
      "Receiving objects:  43% (1717/3993)   \r",
      "Receiving objects:  44% (1757/3993)   \r",
      "Receiving objects:  45% (1797/3993)   \r",
      "Receiving objects:  46% (1837/3993)   \r",
      "Receiving objects:  47% (1877/3993)   \r",
      "Receiving objects:  48% (1917/3993)   \r",
      "Receiving objects:  49% (1957/3993)   \r",
      "Receiving objects:  50% (1997/3993)   \r",
      "Receiving objects:  51% (2037/3993)   \r",
      "Receiving objects:  52% (2077/3993)   \r",
      "Receiving objects:  53% (2117/3993)   \r",
      "Receiving objects:  54% (2157/3993)   \r",
      "Receiving objects:  55% (2197/3993)   \r",
      "Receiving objects:  56% (2237/3993)   \r",
      "Receiving objects:  57% (2277/3993)   \r",
      "Receiving objects:  58% (2316/3993)   \r",
      "Receiving objects:  59% (2356/3993)   \r",
      "Receiving objects:  60% (2396/3993)   \r",
      "Receiving objects:  61% (2436/3993)   \r",
      "Receiving objects:  62% (2476/3993)   \r",
      "Receiving objects:  63% (2516/3993)   \r",
      "Receiving objects:  64% (2556/3993)   \r",
      "Receiving objects:  65% (2596/3993)   \r",
      "Receiving objects:  66% (2636/3993)   \r",
      "Receiving objects:  67% (2676/3993)   \r",
      "Receiving objects:  68% (2716/3993)   \r",
      "Receiving objects:  69% (2756/3993)   \r",
      "Receiving objects:  70% (2796/3993)   \r",
      "Receiving objects:  71% (2836/3993)   \r",
      "Receiving objects:  72% (2875/3993)   \r",
      "Receiving objects:  73% (2915/3993)   \r",
      "Receiving objects:  74% (2955/3993)   \r",
      "Receiving objects:  75% (2995/3993)   \r",
      "Receiving objects:  76% (3035/3993)   \r",
      "Receiving objects:  77% (3075/3993)   \r",
      "Receiving objects:  78% (3115/3993)   \r",
      "Receiving objects:  79% (3155/3993)   \r",
      "Receiving objects:  80% (3195/3993)   \r",
      "Receiving objects:  81% (3235/3993)   \r",
      "Receiving objects:  82% (3275/3993)   \r",
      "Receiving objects:  83% (3315/3993)   \r",
      "Receiving objects:  84% (3355/3993)   \r",
      "Receiving objects:  85% (3395/3993)   \r",
      "Receiving objects:  86% (3434/3993)   \r",
      "Receiving objects:  87% (3474/3993)   \r",
      "Receiving objects:  88% (3514/3993)   \r",
      "Receiving objects:  89% (3554/3993)   \r",
      "Receiving objects:  90% (3594/3993)   \r",
      "Receiving objects:  91% (3634/3993)   \r",
      "Receiving objects:  92% (3674/3993)   \r",
      "Receiving objects:  93% (3714/3993)   \r",
      "Receiving objects:  94% (3754/3993)   \r",
      "remote: Total 3993 (delta 0), reused 0 (delta 0), pack-reused 3993\n",
      "Receiving objects:  95% (3794/3993)   \r",
      "Receiving objects:  96% (3834/3993)   \r",
      "Receiving objects:  97% (3874/3993)   \r",
      "Receiving objects:  98% (3914/3993)   \r",
      "Receiving objects:  99% (3954/3993)   \r",
      "Receiving objects: 100% (3993/3993)   \r",
      "Receiving objects: 100% (3993/3993), 2.12 MiB | 19.56 MiB/s, done.\n",
      "Resolving deltas:   0% (0/2774)   \r",
      "Resolving deltas:   1% (30/2774)   \r",
      "Resolving deltas:   2% (60/2774)   \r",
      "Resolving deltas:   4% (116/2774)   \r",
      "Resolving deltas:   5% (161/2774)   \r",
      "Resolving deltas:   6% (176/2774)   \r",
      "Resolving deltas:  15% (438/2774)   \r",
      "Resolving deltas:  16% (447/2774)   \r",
      "Resolving deltas:  17% (481/2774)   \r",
      "Resolving deltas:  18% (512/2774)   \r",
      "Resolving deltas:  19% (529/2774)   \r",
      "Resolving deltas:  20% (580/2774)   \r",
      "Resolving deltas:  26% (729/2774)   \r",
      "Resolving deltas:  27% (750/2774)   \r",
      "Resolving deltas:  28% (801/2774)   \r",
      "Resolving deltas:  29% (817/2774)   \r",
      "Resolving deltas:  30% (842/2774)   \r",
      "Resolving deltas:  31% (860/2774)   \r",
      "Resolving deltas:  32% (893/2774)   \r",
      "Resolving deltas:  33% (916/2774)   \r",
      "Resolving deltas:  34% (946/2774)   \r",
      "Resolving deltas:  35% (971/2774)   \r",
      "Resolving deltas:  36% (1002/2774)   \r",
      "Resolving deltas:  37% (1028/2774)   \r",
      "Resolving deltas:  38% (1077/2774)   \r",
      "Resolving deltas:  39% (1082/2774)   \r",
      "Resolving deltas:  41% (1163/2774)   \r",
      "Resolving deltas:  42% (1173/2774)   \r",
      "Resolving deltas:  43% (1198/2774)   \r",
      "Resolving deltas:  44% (1226/2774)   \r",
      "Resolving deltas:  45% (1271/2774)   \r",
      "Resolving deltas:  47% (1313/2774)   \r",
      "Resolving deltas:  48% (1339/2774)   \r",
      "Resolving deltas:  49% (1366/2774)   \r",
      "Resolving deltas:  55% (1539/2774)   \r",
      "Resolving deltas:  56% (1554/2774)   \r",
      "Resolving deltas:  57% (1586/2774)   \r",
      "Resolving deltas:  62% (1746/2774)   \r",
      "Resolving deltas:  63% (1763/2774)   \r",
      "Resolving deltas:  64% (1803/2774)   \r",
      "Resolving deltas:  65% (1808/2774)   \r",
      "Resolving deltas:  66% (1833/2774)   \r",
      "Resolving deltas:  67% (1872/2774)   \r",
      "Resolving deltas:  68% (1891/2774)   \r",
      "Resolving deltas:  70% (1942/2774)   \r",
      "Resolving deltas:  71% (1997/2774)   \r",
      "Resolving deltas:  72% (1998/2774)   \r",
      "Resolving deltas:  73% (2026/2774)   \r",
      "Resolving deltas:  74% (2070/2774)   \r",
      "Resolving deltas:  78% (2181/2774)   \r",
      "Resolving deltas:  79% (2192/2774)   \r",
      "Resolving deltas:  82% (2289/2774)   \r",
      "Resolving deltas:  83% (2326/2774)   \r",
      "Resolving deltas:  84% (2335/2774)   \r",
      "Resolving deltas:  87% (2416/2774)   \r",
      "Resolving deltas:  88% (2457/2774)   \r",
      "Resolving deltas:  89% (2470/2774)   \r",
      "Resolving deltas:  90% (2499/2774)   \r",
      "Resolving deltas:  91% (2526/2774)   \r",
      "Resolving deltas:  92% (2560/2774)   \r",
      "Resolving deltas:  93% (2583/2774)   \r",
      "Resolving deltas:  94% (2614/2774)   \r",
      "Resolving deltas:  95% (2640/2774)   \r",
      "Resolving deltas:  98% (2735/2774)   \r",
      "Resolving deltas:  99% (2748/2774)   \r",
      "Resolving deltas: 100% (2774/2774)   \r",
      "Resolving deltas: 100% (2774/2774), done.\n",
      "Collecting regex\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
      "\u001b[K     |████████████████████████████████| 655kB 2.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: regex\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
      "Successfully built regex\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2019.6.8\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/epsdg/pytorch-pretrained-BERT\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'pytorch-pretrained-BERT')\n",
    "\n",
    "! pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zH6ulVK2uyI"
   },
   "source": [
    "## 2. Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 149019,
     "status": "ok",
     "timestamp": 1561604706466,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "4r6hLWYkFBwL",
    "outputId": "75c92ea2-7ae6-4e71-b8f7-2bbd9d53d028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cpus=2\n",
      "device=cuda, type: Tesla T4, CUDA capability: (7, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import requests\n",
    "import zipfile\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "sys.path.insert(0, 'pytorch-pretrained-BERT')\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "print(f'n_cpus={multiprocessing.cpu_count()}')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device={device}, '+\n",
    "      f'type: {torch.cuda.get_device_name(device)}, ' +\n",
    "      f'CUDA capability: {torch.cuda.get_device_capability(device)}')\n",
    "\n",
    "log_date = datetime.now().strftime('%m%d-%H%M')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s: %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    filename='/content/BERT-' + log_date + '.txt',\n",
    "                    filemode='w')\n",
    "\n",
    "logger1 = logging.getLogger('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dh9ywL1Hsuuu"
   },
   "source": [
    "#### Retrieve and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 154063,
     "status": "ok",
     "timestamp": 1561604722025,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "g2k15L9akAM2",
    "outputId": "2d4daffe-1aff-4f4a-ed2c-d55bbeb13306"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building PyTorch model from configuration: {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Converting TensorFlow checkpoint from /content/models/BERT/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Loading TF weight bert/embeddings/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/embeddings/position_embeddings with shape [512, 768]\n",
      "Loading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\n",
      "Loading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
      "Loading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\n",
      "Loading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
      "Loading TF weight bert/pooler/dense/bias with shape [768]\n",
      "Loading TF weight bert/pooler/dense/kernel with shape [768, 768]\n",
      "Loading TF weight cls/predictions/output_bias with shape [30522]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\n",
      "Loading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/bias with shape [768]\n",
      "Loading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\n",
      "Loading TF weight cls/seq_relationship/output_bias with shape [2]\n",
      "Loading TF weight cls/seq_relationship/output_weights with shape [2, 768]\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\n",
      "Initialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'output_bias']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\n",
      "Initialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\n",
      "Initialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\n",
      "Save PyTorch model to /content/models/BERT/uncased_L-12_H-768_A-12/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "MODELS_DIR = '/content/models/BERT/'\n",
    "SOURCE_PATH = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "\n",
    "  # BASE models: 12 layers, Hdim 768, 12 heads\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip'\n",
    "\n",
    "  # LARGE models: 24 layers, Hdim 1024, 16 heads\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip'\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip'\n",
    "\n",
    "  # large, whole word masking\n",
    "  # https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
    "  # https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip\n",
    "\n",
    "model_fname = SOURCE_PATH.split('/')[-1]\n",
    "model_path = os.path.join(MODELS_DIR, model_fname.split('.')[0])\n",
    "\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "    r = requests.get(SOURCE_PATH, stream=True)\n",
    "    with open(os.path.join(MODELS_DIR, model_fname), 'wb') as f:\n",
    "        file_size = int(r.headers[\"content-length\"])\n",
    "        chunk_size = 1000\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            f.write(chunk)\n",
    "\n",
    "    with zipfile.ZipFile(os.path.join(MODELS_DIR, model_fname), 'r') as f:\n",
    "        f.extractall(os.path.join(MODELS_DIR))\n",
    "    os.remove(os.path.join(MODELS_DIR, model_fname))\n",
    "    shutil.move(model_path + '/bert_config.json', model_path + '/config.json')\n",
    "    \n",
    "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "    model_path + '/bert_model.ckpt',\n",
    "    model_path + '/config.json',\n",
    "    model_path + '/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsbnNsmD240i"
   },
   "source": [
    "#### Load & process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16352,
     "status": "ok",
     "timestamp": 1561606516202,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "WQn4UwKfW_B1",
    "outputId": "066dbb1e-14a5-4bcf-b87f-15e13234f67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-tox id 103445 non-tox 300000 tox 144334\n",
      "(547779, 47)\n",
      "train records: 438223 val records: 109556\n"
     ]
    }
   ],
   "source": [
    "TRAIN_VAL_SPLIT = 0.8\n",
    "\n",
    "def get_inputs(df_in, train_val_split):\n",
    "    # Returns: train_texts, train_labels, val_texts, val_labels\n",
    "    #    ( _texts: np.array of str )\n",
    "    #    ( labels: np.array of np.int64 )\n",
    "    train_df = train1[:int(train1.shape[0]*train_val_split)]\n",
    "    val_df = train1[int(train1.shape[0]*train_val_split):]\n",
    "    \n",
    "    train_texts = train_df.comment_text.values\n",
    "    train_labels = train_df.target_int.values.astype('int')\n",
    "    val_texts = val_df.comment_text.values\n",
    "    val_labels = val_df.target_int.values.astype('int')\n",
    "    \n",
    "    return train_texts, train_labels, val_texts, val_labels\n",
    "\n",
    "train_texts, train_labels, val_texts, val_labels = get_inputs(train1, TRAIN_VAL_SPLIT)\n",
    "\n",
    "print(f'train records: {len(train_texts)} val records: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2deUh29f2LiD"
   },
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bj4xD4C32Ojk"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 1\n",
    "ETA = 3e-6\n",
    "OPTIMIZER_WARMUP = 0.05\n",
    "LOG_INTERVAL = 500\n",
    "AMP_OPT_LEVEL = 'O1'\n",
    "GRAD_ACCUM_STEPS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfToPgLF2_8W"
   },
   "source": [
    "#### Tokenize train text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 496892,
     "status": "ok",
     "timestamp": 1561607019088,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "1G7_Lka6XJWz",
    "outputId": "765ce766-6772-42e2-d53d-d7e43f6ae37e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438223/438223 [07:54<00:00, 923.51it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_path, cache_dir=None, do_lower_case=True)\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_len):\n",
    "    ret = np.zeros((len(sentences), max_len))\n",
    "    for i, sentence in enumerate(tqdm(sentences, mininterval=10)):\n",
    "        tokens = tokenizer.tokenize(sentence)[:max_len-2]\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(['[CLS]'] + tokens + ['[SEP]'])\n",
    "        lens.append(len(indexed_tokens))\n",
    "        ret[i, :len(indexed_tokens)] = indexed_tokens\n",
    "    return ret\n",
    "\n",
    "Xt = tokenize(train_texts, tokenizer, MAX_LEN)\n",
    "yt = train_labels\n",
    "train_ds = TensorDataset(torch.tensor(Xt,dtype=torch.long), torch.tensor(yt,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvFLcBRs3LHa"
   },
   "source": [
    "#### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n24FobbPXLs_"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_path, cache_dir=None, num_labels=1)\n",
    "model = model.to(device)\n",
    "\n",
    "model_params = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpJ8kgOY3Tz4"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8952268,
     "status": "ok",
     "timestamp": 1561522299288,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "HoOBpAUuXOay",
    "outputId": "a56e34eb-885f-45c0-8542-97822d7d702e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13695 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 143/13695 [01:31<2:23:26,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1616/13695 [17:35<2:11:51,  1.53it/s, loss=0.234, lr=2.99e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5802/13695 [1:03:13<1:26:00,  1.53it/s, loss=0.178, lr=2.52e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 7045/13695 [1:16:46<1:12:29,  1.53it/s, loss=0.17, lr=2.35e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 11047/13695 [2:00:22<28:49,  1.53it/s, loss=0.168, lr=1.89e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 13118/13695 [2:22:55<06:17,  1.53it/s, loss=0.166, lr=1.66e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13695/13695 [2:29:12<00:00,  1.53it/s, loss=0.164, lr=1.6e-6]\n"
     ]
    }
   ],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=ETA,\n",
    "                     warmup=WARMUP,\n",
    "                     t_total=N_EPOCHS * np.ceil(len(train_texts) / BATCH_SIZE))\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=AMP_OPT_LEVEL, verbosity=1)\n",
    "\n",
    "model = model.train()\n",
    "\n",
    "xentropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "logger1.info(f'Using uncased_L-12_H-768_A-12')\n",
    "logger1.info(f'train hparams:\\n   train recs: {len(train_texts):,}\\n'\n",
    "             + f'   max_len: {MAX_LEN}\\n   n_epochs: {N_EPOCHS}\\n'\n",
    "             + f'   batch size: {BATCH_SIZE}\\n   eta: {ETA}\\n'\n",
    "             + f'   warmup {OPTIMIZER_WARMUP}\\n'\n",
    "             + f'   accumulation steps: {GRAD_ACCUM_STEPS}\\n'\n",
    "             + f'   opt_level: {AMP_OPT_LEVEL}'\n",
    "           )\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    logger1.info(f'epoch {epoch+1} of {N_EPOCHS} training:')\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    tq = tqdm(enumerate(train_loader), total=n_batches, mininterval=30, maxinterval=60)\n",
    "    loss_smoothed = None\n",
    "    for step, batch in tq:\n",
    "        X_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].view(-1,1).to(device)\n",
    "        mask = (X_batch>0).to(device)\n",
    "        y_pred = model(X_batch, attention_mask=mask, labels=None)        \n",
    "\n",
    "        loss = xentropy(y_pred, y_batch).to(device)\n",
    "        \n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "\n",
    "        if (step+1) % GRAD_ACCUM_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        \n",
    "        losses.append(batch_loss)\n",
    "\n",
    "        if (step+1) % LOG_INTERVAL == 0:\n",
    "            loss_mean  = sum(losses[(step+1-LOG_INTERVAL):]) / LOG_INTERVAL\n",
    "            lr = optimizer.get_lr()[0]\n",
    "            logstr = f'step {step+1} of {n_batches} loss {loss_mean:.4f} lr {lr:.4E}'\n",
    "            logger1.info(logstr)\n",
    "            tq.set_postfix(loss=loss_mean, lr=lr)\n",
    "\n",
    "logger1.info('train complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ey1YoOl3bOb"
   },
   "source": [
    "#### Save trained model\n",
    "(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKqBJzB7ACCF"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_FNAME = 'bert_pytorch.bin'\n",
    "SAVED_MODEL_DIR = '/content/saved_models'\n",
    "if not os.path.exists(SAVED_MODEL_DIR):\n",
    "    os.makedirs(SAVED_MODEL_DIR)\n",
    "\n",
    "torch.save(model.state_dict(), os.path.join(SAVED_MODEL_DIR, SAVED_MODEL_FNAME))\n",
    "logger1.info(f'Model saved as {SAVED_MODEL_DIR + \"/\" + SAVED_MODEL_FNAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsk9LZR43iO_"
   },
   "source": [
    "#### Plot training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1561522310659,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "1hLF68ZR-m6N",
    "outputId": "056bd2d0-4a31-40d3-e337-50343d40d99a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train 438k eta 0.000003 batch 32 accum 2 loss 0.164 AUC 0.____\n",
    "plt.plot(losses, 'o', color='b', ms=1, alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZZmclZy3kT1"
   },
   "source": [
    "#### Encode eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117902,
     "status": "ok",
     "timestamp": 1561522479333,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "wFS7cmITXOXJ",
    "outputId": "4f494a33-f530-4783-b150-36a6871bbac2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109556/109556 [01:57<00:00, 933.06it/s]\n"
     ]
    }
   ],
   "source": [
    "Xv = tokenize(val_texts, tokenizer, MAX_LEN)\n",
    "yv = val_labels\n",
    "val_ds = TensorDataset(torch.tensor(Xv,dtype=torch.long), torch.tensor(yv,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIjFSVtj6wtO"
   },
   "source": [
    "#### Load trained model\n",
    "Skip this step if training and evaluating in the same runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3F1XUscz6kyY"
   },
   "outputs": [],
   "source": [
    "SAVED_MODEL_FNAME = 'bert_pytorch.bin'\n",
    "SAVED_MODEL_DIR = '/content/saved_models'\n",
    "model.load_state_dict(torch.load(os.path.join(SAVED_MODEL_DIR, SAVED_MODEL_FNAME)))\n",
    "logger1.info(f'Model loaded from {SAVED_MODEL_DIR + \"/\" + SAVED_MODEL_FNAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBIWAk4G3hBn"
   },
   "source": [
    "#### Generate eval set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822873,
     "status": "ok",
     "timestamp": 1561523643955,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "KiAqw0gNXOP3",
    "outputId": "e96e9df1-898f-426d-a944-f8d1ca6f9701"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3424/3424 [13:42<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "val_preds = []\n",
    "\n",
    "tq = tqdm(enumerate(val_loader), total=len(val_loader), mininterval=10)\n",
    "for i, batch in tq:\n",
    "    X_batch = batch[0].to(device)\n",
    "    logits_batch = model(X_batch,\n",
    "                         attention_mask=(X_batch>0).to(device),\n",
    "                         labels=None)\n",
    "    preds_batch = torch.sigmoid(logits_batch[:, 0])\n",
    "    preds_batch = preds_batch.detach().cpu().squeeze().tolist()\n",
    "    val_preds.extend(preds_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1561525833074,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "Ukvzocr_4aAY",
    "outputId": "bc09f83e-3189-47a3-f3a4-0abafc5caed6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_preds, bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imIrzbU9xJkP"
   },
   "source": [
    "#### Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1192,
     "status": "ok",
     "timestamp": 1561525880985,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "nxJzIUSqwQkl",
    "outputId": "e17525b9-ed85-429c-a23f-0328c2f0cf1a"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "val_preds = np.array(val_preds)\n",
    "val_AUC = metrics.roc_auc_score(val_labels, val_preds)\n",
    "val_acc = metrics.accuracy_score(val_labels.astype('int'), val_preds.astype('int'))\n",
    "logger1.info(f'Eval set AUC = {val_AUC:.4f}')\n",
    "logger1.info(f'Eval set accuracy = {val_acc:.4f}')\n",
    "print(f'AUC {val_AUC:.4f}, acc {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6EyAcvVfVOT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_v4.ipynb",
   "provenance": [
    {
     "file_id": "1RGHO_lRwx46YeT5H14g4x0wiGt5oEwnQ",
     "timestamp": 1560826213011
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
