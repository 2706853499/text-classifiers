{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rtt6IUfZ2QOl"
   },
   "source": [
    "## One-time installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoz_4LhoNdjS"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCxX5ZQY1Iih"
   },
   "source": [
    "#### Download and install NVIDIA Apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWHCFgUfu2Tw"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/apex\n",
    "% cd apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
    "% cd /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lj-TDb-P2UfL"
   },
   "source": [
    "#### Clone & install pretrained BERT repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nebCBnhhA0nP"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/huggingface/pytorch-pretrained-BERT\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'pytorch-pretrained-BERT')\n",
    "\n",
    "! pip install regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zH6ulVK2uyI"
   },
   "source": [
    "## 2. Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1561473357317,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "4r6hLWYkFBwL",
    "outputId": "240d6363-83a1-4bb5-9d27-379e332529f0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "sys.path.insert(0, 'pytorch-pretrained-BERT')\n",
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
    "from pytorch_pretrained_bert import BertConfig\n",
    "\n",
    "print(f'n_cpus={multiprocessing.cpu_count()}')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device={device}, '+\n",
    "      f'type: {torch.cuda.get_device_name(device)}, ' +\n",
    "      f'CUDA capability: {torch.cuda.get_device_capability(device)}')\n",
    "\n",
    "log_date = datetime.now().strftime('%m%d-%H%M')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s: %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    filename='/content/BERT-' + log_date + '.txt',\n",
    "                    filemode='w')\n",
    "\n",
    "logger1 = logging.getLogger('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dh9ywL1Hsuuu"
   },
   "source": [
    "#### Retrieve and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2k15L9akAM2"
   },
   "outputs": [],
   "source": [
    "MODELS_DIR = '/content/models/BERT/'\n",
    "SOURCE_PATH = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "\n",
    "  # BASE models: 12 layers, Hdim 768, 12 heads\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip'\n",
    "\n",
    "  # LARGE models: 24 layers, Hdim 1024, 16 heads\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip'\n",
    "  # 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip'\n",
    "\n",
    "  # large, whole word masking\n",
    "  # https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
    "  # https://storage.googleapis.com/bert_models/2019_05_30/wwm_cased_L-24_H-1024_A-16.zip\n",
    "\n",
    "model_fname = SOURCE_PATH.split('/')[-1]\n",
    "model_path = os.path.join(MODELS_DIR, model_fname.split('.')[0])\n",
    "\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "    r = requests.get(SOURCE_PATH, stream=True)\n",
    "    with open(os.path.join(MODELS_DIR, model_fname), 'wb') as f:\n",
    "        file_size = int(r.headers[\"content-length\"])\n",
    "        chunk_size = 1000\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            f.write(chunk)\n",
    "\n",
    "    with zipfile.ZipFile(os.path.join(MODELS_DIR, model_fname), 'r') as f:\n",
    "        f.extractall(os.path.join(MODELS_DIR))\n",
    "    os.remove(os.path.join(MODELS_DIR, model_fname))\n",
    "    shutil.move(model_path + '/bert_config.json', model_path + '/config.json')\n",
    "    \n",
    "convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n",
    "    model_path + '/bert_model.ckpt',\n",
    "    model_path + '/config.json',\n",
    "    model_path + '/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsbnNsmD240i"
   },
   "source": [
    "#### Load & process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16361,
     "status": "ok",
     "timestamp": 1561473393187,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "WQn4UwKfW_B1",
    "outputId": "1a0ace84-7fe7-4f72-c320-b074edf1a68f"
   },
   "outputs": [],
   "source": [
    "def get_inputs(df_in, train_val_split):\n",
    "    # Returns: train_texts, train_labels, val_texts, val_labels\n",
    "    #    ( _texts: np.array of str )\n",
    "    #    ( labels: np.array of np.int64 )\n",
    "\n",
    "    # ...LOADER CODE...\n",
    "    \n",
    "    return train_texts, train_labels, val_texts, val_labels\n",
    "\n",
    "train_texts, train_labels, val_texts, val_labels = get_inputs(train1, 0.8)\n",
    "\n",
    "print(f'train records: {len(train_texts)} val records: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfToPgLF2_8W"
   },
   "source": [
    "#### Tokenize train text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 473261,
     "status": "ok",
     "timestamp": 1561473950114,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "1G7_Lka6XJWz",
    "outputId": "1fd14c49-1847-4bb6-9c88-cbe68d78611a"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, cache_dir=None,do_lower_case=True)\n",
    "\n",
    "def tokenize(sentences, tokenizer, max_len):\n",
    "    ret = np.zeros((len(sentences), max_len))\n",
    "    for i, sentence in enumerate(tqdm(sentences, mininterval=10)):\n",
    "        tokens = tokenizer.tokenize(sentence)[:max_len-2]\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(['[CLS]'] + tokens + ['[SEP]'])\n",
    "        ret[i, :len(indexed_tokens)] = indexed_tokens\n",
    "    return ret\n",
    "\n",
    "Xt = tokenize(train_df.comment_text.values, tokenizer, MAX_LEN)\n",
    "yt = train_df.target_int.values\n",
    "train_ds = TensorDataset(torch.tensor(Xt,dtype=torch.long), torch.tensor(yt,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvFLcBRs3LHa"
   },
   "source": [
    "#### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n24FobbPXLs_"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_path, cache_dir=None, num_labels=1)\n",
    "model = model.to(device)\n",
    "\n",
    "model_params = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model_params if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model_params if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpJ8kgOY3Tz4"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4530343,
     "status": "ok",
     "timestamp": 1561483326950,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "HoOBpAUuXOay",
    "outputId": "b89c0783-b0b4-4f12-ae25-cc6cc50846c0"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 1\n",
    "ETA = 0.000004\n",
    "log_interval = 100\n",
    "OPT_LEVEL = 'O1'\n",
    "accumulation_steps = 2\n",
    "log_interval = 500\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=ETA,\n",
    "                     warmup=0.05,\n",
    "                     t_total=N_EPOCHS * np.ceil(train_df.shape[0] / BATCH_SIZE))\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=OPT_LEVEL, verbosity=1)\n",
    "\n",
    "model = model.train()\n",
    "\n",
    "xentropy = torch.nn.functional.binary_cross_entropy_with_logits\n",
    "\n",
    "losses = []\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "logger1.info(f'train hparams:\\n   train recs: {train_df.shape[0]:,}\\n'\n",
    "             + f'   max_len: {MAX_LEN}\\n   n_epochs: {N_EPOCHS}\\n'\n",
    "             + f'   batch size: {BATCH_SIZE}\\n   eta: {ETA}\\n'\n",
    "             + f'   accumulation steps: {accumulation_steps}\\n'\n",
    "             + f'   opt_level: {OPT_LEVEL}'\n",
    "           )\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    logger1.info(f'epoch {epoch+1} of {N_EPOCHS} training:')\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    tq = tqdm(enumerate(train_loader), total=n_batches, mininterval=30, maxinterval=60)\n",
    "    loss_smoothed = None\n",
    "    for step, batch in tq:\n",
    "        X_batch = batch[0].to(device)\n",
    "        y_batch = batch[1].view(-1,1).to(device)\n",
    "        mask = (X_batch>0).to(device)\n",
    "        y_pred = model(X_batch, attention_mask=mask, labels=None)        \n",
    "\n",
    "        loss = xentropy(y_pred, y_batch).to(device)\n",
    "        \n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "\n",
    "        if (step+1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        \n",
    "        losses.append(batch_loss)\n",
    "\n",
    "        if (step+1) % log_interval == 0:\n",
    "            loss_mean  = sum(losses[(step+1-log_interval):]) / log_interval\n",
    "            logstr = f'step {step+1} of {n_batches} loss {loss_mean:.4f} lr {optimizer.get_lr()[0]}'\n",
    "            logger1.info(logstr)\n",
    "            tq.set_postfix(loss=loss_mean)\n",
    "\n",
    "logger1.info('train complete.')  #0.169 38%  0.165 46%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save trained model\n",
    "(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKqBJzB7ACCF"
   },
   "outputs": [],
   "source": [
    "mkdir /content/saved_models/\n",
    "FNAME = '/content/saved_models/bert_pytorch.bin'\n",
    "torch.save(model.state_dict(), FNAME)\n",
    "#model.load_state_dict(torch.load(output_model_file ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1561483429642,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "lZcWpwgJyych",
    "outputId": "0186c937-d51f-4b46-92ea-863529600efa"
   },
   "outputs": [],
   "source": [
    "# train 438k eta 0.000004 batch 32 accum 2 loss 0.165 AUC 0.9536\n",
    "plt.plot(losses, 'o', color='b', ms=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZZmclZy3kT1"
   },
   "source": [
    "#### Tokenize eval set text samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116585,
     "status": "ok",
     "timestamp": 1561483558053,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "wFS7cmITXOXJ",
    "outputId": "6a051a8a-1644-40c3-d191-f5ac3ef29eb3"
   },
   "outputs": [],
   "source": [
    "Xv = tokenize(val_df.comment_text.values, tokenizer, MAX_LEN)\n",
    "yv = val_df.target_int.values\n",
    "val_ds = TensorDataset(torch.tensor(Xv,dtype=torch.long), torch.tensor(yv,dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained model\n",
    "Skip this step if training and evaluating in the same runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_FNAME = 'bert_pytorch.bin'\n",
    "SAVED_MODEL_DIR = '/content/saved_models'\n",
    "model.load_state_dict(torch.load(os.path.join(SAVED_MODEL_DIR, SAVED_MODEL_FNAME)))\n",
    "logger1.info(f'Model loaded from {SAVED_MODEL_DIR + \"/\" + SAVED_MODEL_FNAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBIWAk4G3hBn"
   },
   "source": [
    "#### Generate eval set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 821558,
     "status": "ok",
     "timestamp": 1561484503955,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "KiAqw0gNXOP3",
    "outputId": "2a15eda9-6123-46ba-cc1a-ba9ce358472f"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "model.eval()\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "val_preds = []\n",
    "\n",
    "tq = tqdm(enumerate(val_loader), total=len(val_loader), mininterval=10)\n",
    "for i, batch in tq:\n",
    "    X_batch = batch[0].to(device)\n",
    "    logits_batch = model(X_batch,\n",
    "                         attention_mask=(X_batch>0).to(device),\n",
    "                         labels=None)\n",
    "    preds_batch = torch.sigmoid(logits_batch[:, 0])\n",
    "    preds_batch = preds_batch.detach().cpu().squeeze().tolist()\n",
    "    val_preds.extend(preds_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imIrzbU9xJkP"
   },
   "source": [
    "#### Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1561485103645,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "nxJzIUSqwQkl",
    "outputId": "b94d1a9f-8060-4337-c843-6a864d9b02e1"
   },
   "outputs": [],
   "source": [
    "val_preds = np.array(val_preds)\n",
    "val_AUC = metrics.roc_auc_score(val_labels, val_preds)\n",
    "val_acc = metrics.accuracy_score(val_labels.astype('int'), val_preds.astype('int'))\n",
    "logger1.info(f'Eval set AUC = {val_AUC:.4f}')\n",
    "logger1.info(f'Eval set accuracy = {val_acc:.4f}')\n",
    "print(f'AUC {val_AUC:.4f}, acc {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1561484987691,
     "user": {
      "displayName": "Michael Hamby",
      "photoUrl": "",
      "userId": "06612384245860910180"
     },
     "user_tz": 420
    },
    "id": "XFzL8hOezqpW",
    "outputId": "9dbf89b4-c031-4a93-8954-d4b10f7ce9a2"
   },
   "outputs": [],
   "source": [
    "plt.hist(val_preds, bins=50);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_v4.ipynb",
   "provenance": [
    {
     "file_id": "1RGHO_lRwx46YeT5H14g4x0wiGt5oEwnQ",
     "timestamp": 1560826213011
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
