{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61959,
     "status": "ok",
     "timestamp": 1562702010202,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "OfOKa_LZ6qL6",
    "outputId": "a8d9261b-da63-4c81-a58e-512c9492a6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'xlnet'...\n",
      "remote: Enumerating objects: 107, done.\u001b[K\n",
      "remote: Total 107 (delta 0), reused 0 (delta 0), pack-reused 107\u001b[K\n",
      "Receiving objects: 100% (107/107), 129.24 KiB | 1.82 MiB/s, done.\n",
      "Resolving deltas: 100% (51/51), done.\n",
      "Requirement already satisfied: tf_sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.82.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.82)\n",
      "--2019-07-09 19:52:37--  https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.126.128, 2607:f8b0:4001:c03::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.126.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1338042341 (1.2G) [application/zip]\n",
      "Saving to: ‘cased_L-24_H-1024_A-16.zip’\n",
      "\n",
      "cased_L-24_H-1024_A 100%[===================>]   1.25G   114MB/s    in 9.3s    \n",
      "\n",
      "2019-07-09 19:52:46 (138 MB/s) - ‘cased_L-24_H-1024_A-16.zip’ saved [1338042341/1338042341]\n",
      "\n",
      "Archive:  /content/cased_L-24_H-1024_A-16.zip\n",
      "   creating: xlnet_cased_L-24_H-1024_A-16/\n",
      "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.index  \n",
      "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.data-00000-of-00001  \n",
      "  inflating: xlnet_cased_L-24_H-1024_A-16/spiece.model  \n",
      "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt.meta  \n",
      "  inflating: xlnet_cased_L-24_H-1024_A-16/xlnet_config.json  \n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/zihangdai/xlnet\n",
    "\n",
    "! pip install tf_sentencepiece\n",
    "! pip install sentencepiece\n",
    "\n",
    "! wget https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\n",
    "! unzip /content/cased_L-24_H-1024_A-16.zip\n",
    "! rm /content/cased_L-24_H-1024_A-16.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcBsIgHKVkuJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "sys.path.insert(0, '/content/xlnet')\n",
    "\n",
    "from run_classifier import FLAGS\n",
    "FLAGS([None])\n",
    "\n",
    "import function_builder\n",
    "import model_utils\n",
    "from run_classifier import InputExample\n",
    "from run_classifier import file_based_convert_examples_to_features\n",
    "from run_classifier import file_based_input_fn_builder\n",
    "from prepro_utils import preprocess_text, encode_ids\n",
    "from classifier_utils import convert_single_example, PaddingInputExample\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def clear_checkpoint_cache():\n",
    "  '''remove all files from FLAGS.model_dir'''\n",
    "  files = tf.gfile.ListDirectory(FLAGS.model_dir)\n",
    "  for file in files:\n",
    "    tf.gfile.Remove(os.path.join(FLAGS.model_dir, file))\n",
    "        \n",
    "def get_lens():\n",
    "  '''retrieve #_records for train & eval datasets'''\n",
    "  with open('./dataset_lens.json') as file:\n",
    "    lens = json.load(file)\n",
    "    ret = lens['train'], lens['val']\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nerRoYYs4J4h"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1562702783324,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "mVkmVQ7p_JSQ",
    "outputId": "a10785fc-ce46-4dbf-9458-08447c2cf88a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU devices:\n",
      "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 4624636520845270748),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5862292550072502558),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8113030125432651549),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14384874521711867188),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 1112809580184861644),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 3079818582861333513),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14918201319546221024),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11325530939983350382),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9260931485257681598),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17589247473036768979),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9402764591310561304)]\n"
     ]
    }
   ],
   "source": [
    "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "\n",
    "with tf.Session(tpu_address) as session:\n",
    "  print('TPU devices:')\n",
    "  pprint.pprint(session.list_devices())\n",
    "\n",
    "  with open('/content/adc.json', 'r') as f:\n",
    "    auth_info = json.load(f)\n",
    "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddH594PD_xHq"
   },
   "outputs": [],
   "source": [
    "MODEL_SPEC = 'xlnet_cased_L-24_H-1024_A-16'\n",
    "BUCKET_NAME = _________\n",
    "\n",
    "gcs_path = 'gs://' + BUCKET_NAME\n",
    "pretrained_model_path = gcs_path + '/' + MODEL_SPEC\n",
    "\n",
    "TRAIN_TFREC_FILE_ = 'train.tf_record'\n",
    "VAL_TFREC_FILE_ = 'val.tf_record'\n",
    "TEST_TFREC_FILE_ = 'test.tf_record'\n",
    "\n",
    "LABEL_LIST = [\"0\", \"1\"]\n",
    "\n",
    "FLAGS.task_name = 'xlnet_test'\n",
    "FLAGS.use_tpu = True\n",
    "FLAGS.num_hosts = 1            # single TPU for colab\n",
    "FLAGS.num_core_per_host = 8    # 8 cores per cloud TPU v2\n",
    "FLAGS.tpu = tpu_address\n",
    "FLAGS.overwrite_data = True\n",
    "FLAGS.max_seq_length = 512\n",
    "\n",
    "FLAGS.dropout = 0.1\n",
    "FLAGS.dropatt = 0.1\n",
    "\n",
    "FLAGS.learning_rate = 2e-6\n",
    "FLAGS.train_batch_size = 16\n",
    "FLAGS.train_steps = 10000\n",
    "FLAGS.warmup_steps = 800\n",
    "FLAGS.weight_decay = 0.00\n",
    "FLAGS.decay_method = 'poly'    # ['poly', 'cos']\n",
    "\n",
    "FLAGS.eval_batch_size = 128\n",
    "FLAGS.predict_batch_size = 128\n",
    "\n",
    "FLAGS.iterations = 1000        # iterations per loop, NOT total train steps\n",
    "FLAGS.save_steps = 2000        # >= iterations\n",
    "FLAGS.eval_all_ckpt = False\n",
    "MAX_SAVED_CHECKPOINTS = 3\n",
    "\n",
    "FLAGS.model_dir = gcs_path + '/model'    # checkpoints created during finetuning\n",
    "FLAGS.output_dir = gcs_path + '/output'  # tf_record files (inputs)\n",
    "FLAGS.predict_dir = gcs_path + '/predictions'\n",
    "FLAGS.spiece_model_file = './' + MODEL_SPEC + '/spiece.model' # local FS\n",
    "FLAGS.model_config_path = pretrained_model_path + '/xlnet_config.json' # must be on GCS\n",
    "FLAGS.init_checkpoint = pretrained_model_path + '/xlnet_model.ckpt' # must be on GCS\n",
    "\n",
    "train_tf_rec_file = FLAGS.output_dir + '/' + TRAIN_TFREC_FILE_\n",
    "val_tf_rec_file = FLAGS.output_dir + '/' + VAL_TFREC_FILE_\n",
    "test_tf_rec_file = FLAGS.output_dir + '/' + TEST_TFREC_FILE_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9PuU0QDHcPyi"
   },
   "outputs": [],
   "source": [
    "# ONE TIME PER MODEL SPEC - move pretrained model to GS\n",
    "model_files = os.listdir('./' + MODEL_SPEC)\n",
    "for file in model_files:\n",
    "  os.system('gsutil cp ./' + MODEL_SPEC + '/' + file + ' ' + pretrained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56406,
     "status": "ok",
     "timestamp": 1562647362865,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "qoT1wOos8ZCH",
    "outputId": "e9d766e1-d20d-4cf8-eb3e-bb78330be08c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train records: 1325501 val records: 331376\n"
     ]
    }
   ],
   "source": [
    "# ONE TIME PER FEATURE SET - import data and gen features\n",
    "\n",
    "def load_data():\n",
    "  # ... ...\n",
    "  return train_df, val_df\n",
    "\n",
    "train_df, val_df = load_data()\n",
    "\n",
    "print(f'train records: {len(train_df)} val records: {len(val_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1848825,
     "status": "ok",
     "timestamp": 1562629391005,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "jK1CK9sxAC-d",
    "outputId": "e2e05d29-1ecf-4045-c8b0-b67e2245ab49"
   },
   "outputs": [],
   "source": [
    "# ONE TIME PER FEATURE SET: encode inputs & convert to tf_record\n",
    "#\n",
    "# In the original xlnet.run_classifier.py, inputs are converted to features, then \n",
    "# saved as tf_record files every time a train or eval routine is initiated.\n",
    "# If reusing features already cached to output_dir, skip this processing step.\n",
    "#\n",
    "# Length of each dataset is required for computing eval steps, so lengths\n",
    "# are persisted to local FS as 'dataset_lens.json'.\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(FLAGS.spiece_model_file)\n",
    "\n",
    "def tokenize_fn(text):\n",
    "  text = preprocess_text(text, lower=False)\n",
    "  return encode_ids(sp, text)\n",
    "\n",
    "def create_tf_rec_inputs(df_in, file_out, type=None):\n",
    "  assert type in ['train', 'val', 'test']\n",
    "  examples = []\n",
    "  for (idx, row) in tqdm(df_in.iterrows(), total=len(df_in), mininterval=10):\n",
    "\n",
    "    if type in ['train', 'val']:\n",
    "      example = InputExample(idx, row.comment_text, label=row.label)\n",
    "    elif type == 'test':\n",
    "      example = InputExample(idx, row.comment_text)\n",
    "\n",
    "    examples.append(example)\n",
    "\n",
    "  if type == 'train':\n",
    "    np.random.shuffle(examples)\n",
    "  \n",
    "  if type == 'val':\n",
    "    # eval examples must be padded to multiple of batch size\n",
    "    while len(examples) % FLAGS.eval_batch_size != 0:\n",
    "      examples.append(PaddingInputExample())\n",
    "    assert len(examples) % FLAGS.eval_batch_size == 0\n",
    "        \n",
    "  file_based_convert_examples_to_features(examples,\n",
    "                                          LABEL_LIST,\n",
    "                                          FLAGS.max_seq_length,\n",
    "                                          tokenize_fn,\n",
    "                                          file_out, 1)\n",
    "\n",
    "  return len(examples)\n",
    "\n",
    "train_len = create_tf_rec_inputs(train_df, train_tf_rec_file, type='train')\n",
    "val_len = create_tf_rec_inputs(val_df, val_tf_rec_file, type='val')\n",
    "#create_tf_rec_inputs(test_df, test_tf_rec_file, type='test')\n",
    "\n",
    "lens = {'train': train_len,\n",
    "       'val': val_len}\n",
    "with open('./dataset_lens.json', 'w') as file:\n",
    "  json.dump(lens, file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2659,
     "status": "ok",
     "timestamp": 1562702798080,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "i7nUjsXfAszx",
    "outputId": "6cb89140-053b-4640-b603-387017280f2b"
   },
   "outputs": [],
   "source": [
    "! gsutil ls $pretrained_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaPWBXMqr8is"
   },
   "outputs": [],
   "source": [
    "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_address)\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=FLAGS.model_dir,\n",
    "    save_checkpoints_steps=FLAGS.save_steps,\n",
    "    keep_checkpoint_max=MAX_SAVED_CHECKPOINTS,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations,\n",
    "        num_shards=FLAGS.num_hosts * FLAGS.num_core_per_host,\n",
    "        per_host_input_for_training=is_per_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2s03ti5rGNJy"
   },
   "outputs": [],
   "source": [
    "# from xlnet.run_classifier.py -- added AUC to metric_fn.\n",
    "\n",
    "def get_model_fn(n_class):\n",
    "  def model_fn(features, labels, mode, params):\n",
    "    #### Training or Evaluation\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    #### Get loss from inputs\n",
    "    if FLAGS.is_regression:\n",
    "      (total_loss, per_example_loss, logits\n",
    "          ) = function_builder.get_regression_loss(FLAGS, features, is_training)\n",
    "    else:\n",
    "      (total_loss, per_example_loss, logits\n",
    "          ) = function_builder.get_classification_loss(\n",
    "          FLAGS, features, n_class, is_training)\n",
    "\n",
    "    #### Check model parameters\n",
    "    num_params = sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
    "    tf.logging.info('#params: {}'.format(num_params))\n",
    "\n",
    "    #### load pretrained models\n",
    "    scaffold_fn = model_utils.init_from_checkpoint(FLAGS)\n",
    "\n",
    "    #### Evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "      assert FLAGS.num_hosts == 1\n",
    "\n",
    "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
    "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        eval_input_dict = {\n",
    "            'labels': label_ids,\n",
    "            'predictions': predictions,\n",
    "            'weights': is_real_example\n",
    "        }\n",
    "        accuracy = tf.metrics.accuracy(**eval_input_dict)\n",
    "\n",
    "        auc = tf.metrics.auc(**eval_input_dict)\n",
    "        \n",
    "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "        return {\n",
    "            'eval_accuracy': accuracy,\n",
    "            'eval_auc': auc,\n",
    "            'eval_loss': loss}\n",
    "\n",
    "      def regression_metric_fn(\n",
    "          per_example_loss, label_ids, logits, is_real_example):\n",
    "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "        pearsonr = tf.contrib.metrics.streaming_pearson_correlation(\n",
    "            logits, label_ids, weights=is_real_example)\n",
    "        return {'eval_loss': loss, 'eval_pearsonr': pearsonr}\n",
    "\n",
    "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
    "\n",
    "      #### Constucting evaluation TPUEstimatorSpec with new cache.\n",
    "      label_ids = tf.reshape(features['label_ids'], [-1])\n",
    "\n",
    "      if FLAGS.is_regression:\n",
    "        metric_fn = regression_metric_fn\n",
    "      else:\n",
    "        metric_fn = metric_fn\n",
    "      metric_args = [per_example_loss, label_ids, logits, is_real_example]\n",
    "\n",
    "      if FLAGS.use_tpu:\n",
    "        eval_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=total_loss,\n",
    "            eval_metrics=(metric_fn, metric_args),\n",
    "            scaffold_fn=scaffold_fn)\n",
    "      else:\n",
    "        eval_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=total_loss,\n",
    "            eval_metric_ops=metric_fn(*metric_args))\n",
    "\n",
    "      return eval_spec\n",
    "\n",
    "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "      label_ids = tf.reshape(features[\"label_ids\"], [-1])\n",
    "\n",
    "      predictions = {\n",
    "          \"logits\": logits,\n",
    "          \"labels\": label_ids,\n",
    "          \"is_real\": features[\"is_real_example\"]\n",
    "      }\n",
    "\n",
    "      if FLAGS.use_tpu:\n",
    "        output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "            mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
    "      else:\n",
    "        output_spec = tf.estimator.EstimatorSpec(\n",
    "            mode=mode, predictions=predictions)\n",
    "      return output_spec\n",
    "\n",
    "    #### Configuring the optimizer\n",
    "    train_op, learning_rate, _ = model_utils.get_train_op(FLAGS, total_loss)\n",
    "\n",
    "    monitor_dict = {}\n",
    "    monitor_dict[\"lr\"] = learning_rate\n",
    "\n",
    "    #### Constucting training TPUEstimatorSpec with new cache.\n",
    "    if FLAGS.use_tpu:\n",
    "      #### Creating host calls\n",
    "      if not FLAGS.is_regression:\n",
    "        label_ids = tf.reshape(features['label_ids'], [-1])\n",
    "        predictions = tf.argmax(logits, axis=-1, output_type=label_ids.dtype)\n",
    "        is_correct = tf.equal(predictions, label_ids)\n",
    "        accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "        monitor_dict[\"accuracy\"] = accuracy\n",
    "\n",
    "        host_call = function_builder.construct_scalar_host_call(\n",
    "            monitor_dict=monitor_dict,\n",
    "            model_dir=FLAGS.model_dir,\n",
    "            prefix=\"train/\",\n",
    "            reduce_fn=tf.reduce_mean)\n",
    "      else:\n",
    "        host_call = None\n",
    "\n",
    "      train_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
    "          mode=mode, loss=total_loss, train_op=train_op, host_call=host_call,\n",
    "          scaffold_fn=scaffold_fn)\n",
    "    else:\n",
    "      train_spec = tf.estimator.EstimatorSpec(\n",
    "          mode=mode, loss=total_loss, train_op=train_op)\n",
    "\n",
    "    return train_spec\n",
    "\n",
    "  return model_fn\n",
    "\n",
    "\n",
    "model_fn = get_model_fn(len(LABEL_LIST) if LABEL_LIST is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1562702804378,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "D4_6PLA5ACx8",
    "outputId": "d108522c-7d15-4274-ecaf-aaa83eee3e0c"
   },
   "outputs": [],
   "source": [
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=FLAGS.use_tpu,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=FLAGS.train_batch_size,\n",
    "    predict_batch_size=FLAGS.predict_batch_size,\n",
    "    eval_batch_size=FLAGS.eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1562702805637,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "T-BpeLnPGNP5",
    "outputId": "77299102-d3e0-414c-9a92-a69bfe831fd8"
   },
   "outputs": [],
   "source": [
    "train_input_fn = file_based_input_fn_builder(\n",
    "  input_file=train_tf_rec_file,\n",
    "  seq_length=FLAGS.max_seq_length,\n",
    "  is_training=True,\n",
    "  drop_remainder=True)\n",
    "\n",
    "train_len, val_len = get_lens()\n",
    "print('train len', train_len, 'val len', val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rG0frmqcLjcW"
   },
   "outputs": [],
   "source": [
    "clear_checkpoint_cache()\n",
    "tf.gfile.ListDirectory(FLAGS.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4561680,
     "status": "ok",
     "timestamp": 1562707403114,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "euyXj4gRhRmn",
    "outputId": "e270ff07-3baa-4747-e7d3-e5c0a9960fb6"
   },
   "outputs": [],
   "source": [
    "FLAGS.train_steps = 10000\n",
    "estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1562707577743,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "vrF87I0GgPeQ",
    "outputId": "a4641536-0936-48cd-f4dc-bdd140cfc5ef"
   },
   "outputs": [],
   "source": [
    "eval_input_fn = file_based_input_fn_builder(\n",
    "    input_file=val_tf_rec_file,\n",
    "    seq_length=FLAGS.max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1562707608745,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "d3oxZuzkAPtD",
    "outputId": "25c7391d-7137-4e22-f111-5a450963331f"
   },
   "outputs": [],
   "source": [
    "steps_and_files = []\n",
    "filenames = tf.gfile.ListDirectory(FLAGS.model_dir)\n",
    "\n",
    "for filename in filenames:\n",
    "  if filename.endswith(\".index\"):\n",
    "    ckpt_name = filename[:-6]\n",
    "    cur_filename = os.path.join(FLAGS.model_dir, ckpt_name)\n",
    "    global_step = int(cur_filename.split(\"-\")[-1])\n",
    "    tf.logging.info(\"Add {} to eval list.\".format(cur_filename))\n",
    "    steps_and_files.append([global_step, cur_filename])\n",
    "steps_and_files = sorted(steps_and_files, key=lambda x: x[0])\n",
    "\n",
    "if not FLAGS.eval_all_ckpt:\n",
    "  steps_and_files = steps_and_files[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2572381,
     "status": "ok",
     "timestamp": 1562710206974,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "syLeMORZBI6b",
    "outputId": "c670ac81-ae08-46be-ee9b-aa4bc21e95c6"
   },
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "_, val_len = get_lens()\n",
    "# for tpu evaluation, must pass the number of eval steps\n",
    "eval_steps = val_len // FLAGS.eval_batch_size\n",
    "print('eval steps', eval_steps)\n",
    "\n",
    "for global_step, filename in sorted(steps_and_files, key=lambda x: x[0]):\n",
    "  ret = estimator.evaluate(\n",
    "      input_fn=eval_input_fn,\n",
    "      steps=eval_steps,\n",
    "      checkpoint_path=filename)\n",
    "  \n",
    "  ret[\"step\"] = global_step\n",
    "  ret[\"path\"] = filename\n",
    "\n",
    "  eval_results.append(ret)\n",
    "\n",
    "  tf.logging.info(\"=\" * 80)\n",
    "  log_str = \"Eval result | \"\n",
    "  for key, val in sorted(ret.items(), key=lambda x: x[0]):\n",
    "    log_str += \"{} {} | \".format(key, val)\n",
    "  tf.logging.info(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1562710210849,
     "user": {
      "displayName": "michael hamby",
      "photoUrl": "",
      "userId": "11458401093116257828"
     },
     "user_tz": 420
    },
    "id": "b25ktRlMG8FU",
    "outputId": "d5d5a501-e5ea-4784-d888-663edf5c001e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_accuracy': 0.93880713,\n",
       "  'eval_auc': 0.9182491,\n",
       "  'eval_loss': 0.25729603,\n",
       "  'global_step': 10000,\n",
       "  'loss': 0.26374766,\n",
       "  'path': 'gs://xlnet422/model/model.ckpt-10000',\n",
       "  'step': 10000}]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9u1q62hG4v8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XLNet_v5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
